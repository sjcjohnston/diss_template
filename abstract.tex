% This is where the body of your abstract goes, limited to 150 words
% for a thesis, and 350 words for a dissertation or document.  The
% word count limits apply to the regular Abstract in the thesis and
% to the separate Special Abstract.  Use the same text for both; just
% adjust the margins and heading.  The abstract should summarize your
% work.  The UMI booklet listed in the resources section of the U of
% A manual provides some writing tips.  The abstract for a dissertation
% or document may be longer than one page; word count is more important
% than page length in this section.
% 
% If you are doing a paper submission, submit one copy of the special 
% abstract, and two extra copies of your title page, in the box with 
% the final copies of your thesis.  If you are doing an electronic
% submission, you can ignore the special abstract.


Speech in a noisy background presents a challenge for the recognition of that speech both by human listeners and by computers tasked with understanding human speech (automatic speech recognition; ASR).  Years of research have resulted in many solutions, though none so far have completely solved the problem.  Current solutions generally require some form of estimation of the noise, in order to remove it from the signal. The limitation is that noise can be highly unpredictable and highly variable, both in form and loudness.

The present report proposes a method of recording a speech signal in a noisy environment that largely prevents noise from reaching the recording microphone.  This method utilizes the human skull as a noise-attenuation device by placing the microphone in the ear canal.  For further noise dampening, a pair of noise-reduction earmuffs are used over the speakers' ears.

A corpus of speech was recorded with a microphone in the ear canal, while also simultaneously recording speech at the mouth.  Noise was emitted from a loudspeaker in the background.  Following the data collection, the speech recorded at the ear was analyzed.  A substantial noise-reduction benefit was found over mouth-recorded speech.  However, this speech was missing much high-frequency information.  With minor processing, mid-range frequencies were amplified, increasing the intelligibility of the speech.

A human perception task was conducted using both the ear-recorded and mouth-recorded speech.  Participants in this experiment were significantly more likely to understand ear-recorded speech over the noisy, mouth-recorded speech.  Yet, participants found mouth-recorded speech with no noise the easiest to understand.

These recordings were also used with an ASR system.  Since the ear-recorded speech is missing much high-frequency information, it did not recognize the ear-recorded speech readily.  However, when an acoustic model was trained low-pass filtered speech, performance improved.

These experiments demonstrated that humans, and likely an ASR system, with additional training, would be able to more easily recognize ear-recorded speech than speech in noise.  Further speech processing and training may be able to improve the signal's intelligibility for both human and automatic speech recognition.

